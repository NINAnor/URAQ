---
title: "Urban Air Quality"
subtitle: "[NO_URAQ_000 to NO_URAQ_004] - Urban Air Quality - Particulate Matter 2.5 concentration in urban areas"
format: 
  html:
    embed-resources: true
    code-fold: true
    toc: true
    toc-title: Contents
    toc-depth: 3
    smooth-scroll: true
execute: 
  cache: true
author:
  - name: Sylvie Clappe # Enter name
    email: sylvie.clappe@nina.no  # Enter email
    affiliations:
      - id: myID
        name: Norwegian Institute for Nature Research # Enter affiliations
  - name: Bálint Czúcz            #  Enter subsequent authors like this, or remove if not relevant
    email: balint.czucz@nina.no
    affiliations:
      - ref: myID               # To reuse affiliations referecen the id like this
date: July 10, 2025# Enter date 
callout-icon: false
lightbox: true
css: ../../../style.css
code-links:
      - text: Add a review
        icon: github
        href: https://github.com/NINAnor/ecRxiv
---

<!--# This is a template for how to document the indicator analyses. Make sure also to not change the order, or modify, the headers, unless you really need to. This is because it easier to read if all the indicators are presented using the same layout. If there is one header where you don't have anything to write, just leave the header as is, and don't write anything below it. If you are providing code, be careful to annotate and comment on every step in the analysis. Before starting it is recommended to fill in as much as you can in the metadata file. This file will populate the initial table in your output.-->

<!--# Load all you dependencies here -->

```{r setup}
#| include: false
library(knitr)
library(tidyverse)
library(kableExtra)
library(terra)
library(sf)
library(dplyr)
library(readxl)
library(httr2)
library(glue)
library(tictoc)
library(duckdb)
library(duckdbfs)
library(duckspatial)
library(mirai)
library(purrr)
library(stringr)
library(exactextractr)
library(carrier)

knitr::opts_chunk$set(echo = TRUE)
```

```{r source}
#| echo: false
source(here::here("_common.R"))
```

```{r}
#| echo: false
meta <- readxl::read_xlsx("../metadata.xlsx")
st <- meta |>
  filter(Variable == "status") |>
  pull(Value)
version <- meta |>
  filter(Variable == "Version") |>
  pull(Value)
auth <- meta |>
  filter(Variable == "authors") |>
  pull(Value)
year <- meta |>
  filter(Variable == "yearAdded") |>
  pull(Value)
id <- meta |>
  filter(Variable == "indicatorID") |>
  pull(Value)
name <- meta |>
  filter(Variable == "indicatorName") |>
  pull(Value)
url <- meta |>
  filter(Variable == "url") |>
  pull(Value)

meta <- meta |>
  mutate(Variable = case_match(Variable,
    "indicatorID" ~ "Indicator ID" ,
    "indicatorName" ~ "Indicator Name",
    "country" ~ "Country",
    "continent" ~ "Continent",
    "ECT" ~ "Ecosystem Condition Typology Class",
    "yearAdded" ~ "Year added",
    "yearLastUpdate" ~ "Last update",
    .default = Variable
   )
  ) |>
  filter(Variable != "authors")

```

<!--# The following parts are autogenerated. Do not edit. -->

```{r}
#| echo: false
#| results: asis
status(st)
```

::: {layout-ncol="2"}



> **Recomended citation**: `r paste(auth, " ", year, ". ", name, " (ID: ", id, ") ", "v. ", version, ". ecRxiv: https://view.nina.no/ecRxiv/", sep="")`

> **Version**: `r version`

:::

```{=html}
<details>
<summary>Show metadata</summary>
```

```{r tbl-meta}
#| tbl-cap: 'Indicator metadata'
#| echo: false
#| warning: false

meta |>
  select(Variable, Value) |>
  kbl(col.names = NULL) 

```

```{=html}
</details>
```

::: {.callout-tip collapse="true"}

## Logg

<!--# Update this logg with short messages for each update -->
- 01 Jan. 1901 - Original PR
:::


<hr />

<!--# Document you work below.  -->

## 1. Summary
***What is the urban air quality indicators?*** \
Urban air quality can be defined as the degree to which the air in urban areas (*e.g.,* cities, towns, suburbs) is free from pollutants. 

***How to measure air quality in an urban area?*** \
Air quality can be measured by the presence of various pollutants in the air. In this report, we focused on the concentration of particulate matter 2.5. There are 2 major steps in calculating this indicator:

1. Identify the total area of urban areas.
2. Within this area, calculate the average yearly concentration of particulate matter 2.5 and ozone.

***How to use and interpret this indicator?*** \
There are several ways of defining urban areas. That is why, in this document, we present two variations of the indicator based on two different definitions of the urban areas. We also present different spatial breakdowns of the two indicators. We recommend to use URAQ_004 as it relies on the most ecologically correct definition. It however does not follow the official guidance from the European Commission. If users need to report this indicator in an official EU reporting, we recommend to use URAQ_000 instead.

<!--# 

With a maximum of 300 words, describe the indicator in general terms as you would to a non-expert. Think of this as a kind of commmon language summary. It is a good idea to include a bullet point list of the spesific steps in the workflow. Include a mention of the following aspects:

What does the metric represent?
Why is this relevant for describing ecosystem condition in this ecosystem?
What are the main anthropogenig impact factors?
What kind of data is used? 
Shortly, how is the data customized (modified, estimated, integarted) to fit its purpuse as an indicator?
What is the current status of  the metric (can it be used or is it still in development)?
How should the metric be used and interpretted, and how should it not be used/interpretted?

 -->

## 2. About the underlying data
We used six datasets whose origin and use are described below. Further characteristics of each dataset are described in the subsections of this chapter below.

|| Origin | Used for |
|---------|-----|------|
| **Grunnkart**     |  NIBIO   | Define urban areas as the "settlements and other artificial areas" class|
| **Administrative boundaries - Local Administrative Units**      |  European Commission    | define urban areas as Local Administrative Units (*i.e.,* municipalities) in Norway | 
| **PM2.5 concentration maps**  | Norwegian Environmental Protection Agency (Miljødirektoratet)  | Calculate mean PM2.5 concentration over different spatial scales.| 
| **Administrative boundaries - DEGURBA**      | European Commission    | Used to breakdown the results in different spatial units: "cities" (`DEGURBA = 1`), "towns and suburbs" (`DEGURBA = 2`), and "rural areas" (`DEGURBA = 2`) |
| **Administrative boundaries for municipalities**      |  Kartverkert    | Used to update **Administrative boundaries - Local Administrative Units** provided by the European Commission to 2024 instead of 2023. In Norway, municipalities' numbers significantly changed between these two years. In addition, Ålesund municipality was divided in two municipalities.|
| **Administrative identifiers for municipalities and fylke**| Kartverkert    | Used to correct the municipalities' numbers and add Fylke number to provide another level of spatial disaggregation.|

<!--# Describe the data you have used in more detail, it's origin, biases, availabilit ect.-->

### 2.1 Spatial and temporal resolution and extent
|| Spatial scale | Spatial Resolution | Spatial Accuracy |
|---------|-----|------|------|
| **Grunnkart**     |  National - Norway   | MMU: 2-50m, depending on the ecosystem type mapped    | 1 to 500m depending on the dataset used to create the polygon |
| **Administrative boundaries - Local Administrative Units**      |  National - Norway    | NA | NA  |
| **Administrative boundaries - DEGURBA**      | National - Norway    | NA |  NA |
| **Administrative boundaries for municipalities**      | National - Norway    | NA |  NA |
| **PM2.5 concentration maps**      | Municipal, covering the whole of Norway    | 100m |  NA |
| **Administrative identifiers for municipalities and fylke**     | National - Norway    | NA |  NA | 

<!--# Describe the temporal and spatial resolution and extent of the data used -->

### 2.2 Original units
|| Original units |
|---------|-----|
| **Grunnkart**     | this dataset is a composite of multiple geospatial datasets that have been harmonised, cleaned and standardised for ecosystem accounting.  |
| **Administrative boundaries - Local Administrative Units**      | Municipalities' boundaries |
| **Administrative boundaries - DEGURBA**      | NA |
| **Administrative boundaries for municipalities**     | Municipalities' boundaries including marine sections for coastal municipalities |  
| **PM2.5 concentration maps** | Station measurement of PM2.5 concentration in ug/m3. These local measurements have been used to model maps of concentration over all municipalities in Norway based on an air quality model as used for operational air quality forecasting for Norway at the Norwegian Meteorological Institute.|
| **Administrative identifiers for municipalities and fylke**     | NA |


<!--# What are the original units for the most relevant variables in the data-->

### 2.3 Additional comments about the dataset
|| Origin | Year | Format |
|---------|-----|------|------|
| **Grunnkart**     | NIBIO   |    NA (released year: 2025) | vector |
| **Administrative boundaries - Local Administrative Units**      | European Commission    |  2023   |  vector |
| **Administrative boundaries - DEGURBA**      | European Commission     |     2024 |    excel file |
| **Administrative boundaries for municipalities**    | Kartvetkert    |    2024 |  vector |
| **PM2.5 concentration maps**  | Norwegian Environmental Protection Agency (Miljødirektoratet)    |    2016 - 2023, annula data |  raster |
| **Administrative identifiers for municipalities and fylke**      | Kartverkert    |     2024 |   excel file |

<!--# Text here -->

#### 2.3.1 Instructions for citing, using and accessing data
||Publically accessible| Data and metadata available Available at|
|---------|-----|-----|
| **Grunnkart**     | No, upon request   |     NIBIO: https://kartkatalog.geonorge.no/metadata/grunnkart-for-bruk-i-arealregnskap-testversjon-1/28c28e3a-d88f-4a34-8c60-5efe6d56a44d. Also available locally on the NINA server (refer to the list of path in the Analyses section)|
| **Administrative boundaries - Local Administrative Units**      | Yes    | Europan Commission GISCO service: https://ec.europa.eu/eurostat/web/gisco/geodata/statistical-units/local-administrative-units. Also available locally on the NINA server (refer to the list of path in the Analyses section)|
| **Administrative boundaries - DEGURBA**      | Yes    | European Commission: https://ec.europa.eu/eurostat/web/nuts/local-administrative-units. Also available locally on the NINA server (refer to the list of path in the Analyses section) |
| **Administrative boundaries for municipalities**    | Yes    | Kartverkert: https://kartkatalog.geonorge.no/metadata/administrative-enheter-kommuner/041f1e6e-bdbc-4091-b48f-8a5990f3cc5b. Also available locally on the NINA server (refer to the list of path in the Analyses section) |
| **PM2.5 concentration maps**  | Yes | Miljødirektoratet: https://airquality-expert.met.no/. Also available on the NINA server (refer to the list of path in the Analyses section)|
| **Administrative identifiers for municipalities and fylke**      | Yes | Kartverkert: Available from Kartverkert here:https://www.kartverket.no/til-lands/fakta-om-norge/norske-fylke-og-kommunar. Locally modified and available on the NINA server (refer to the list of path in the Analyses section)|

<!--# Is the data openly available? If not, how can one access it? What are the key references to the datasets?   -->


## 3. Indicator properties

### 3.1 Ecosystem Condition Typology Class (ECT)
The percentage of urban green spaces in urban ecosystems is part of A2 - Abiotic Chemical Characteristics as it describes part of the chemical composition of urban ecosystems.
<!--# 

Describe the rationale for assigning the indicator to the ECT class. See https://oneecosystem.pensoft.net/article/58218/
This doesnt need to be very long. Maybe just a single sentence. 

-->

### 3.2 Ecosystem condition characteristic
The concentration of PM2.5 in the air measures the level of pollution of the air in urban ecosystems. This indicator is particularly important as it underpins people's health which decreases with the incearse of PM2.5 concentration in the air. From an ecosystem perspective, concentration of PM2.5 has also been shown to increase acidity in aquatic ecosystems and reduce the leaf litter breakdown (@pm2.5_lit).

<!--# 

Describe the ecosystem condition characteristic represented in the indicator. See 10.3897/oneeco.6.e58218 for information on what these characteristics might be.
For example, and indicator called 'Trenching in mires' could be made to represent an ecosystem characteristic 'Intact hydrology'. The term 'characteristic' is used similar to the term 'criteria' in Multiple Criteria Decition Making.  

-->

### 3.3 Other standards
In this documentation, we present different variations of the air quality indicator based on PM2.5 concentration. We recommend to use URAQ_004 as it relies upon the most ecologically correct definition, in line with teh System of Environmental Economic Accounting - Ecosystem Accounting (United Nations, 2024). It however does not follow the official guidance from the European Commission for national reporting under EU Regulation 2024/3024 (@eu-2024-3024). If users need to report this indicator in an official EU reporting, we recommend to use URAQ_000.

<!--# Optional: Add text about other spesific standards, e.g. national standards, and how the indicator relates to these -->

### 3.4 Collinearities with other indicators
This indicator might present some correlations with the Tree Cover Density and Urban Green Areas indicators. Green urban ecosystems provide the air filtration service which allows to decrease the concentration of PM2.5 in that air. Hence a correlation between this indicators and any other condition indicators directly and indirectly including green urban ecosystems in their calculations.

<!--# Describe known collinearities with other metrices (indicators or variables) that could become problematic if they were also included in the same Ecosystem Condition Assessment as the indicator described here. -->


### 3.5 Impact factors
The concentration of PM2.5 in the air is entirely due to anthropogenic factors. Human activities through industrial releases or transportations, determines the amount of PM2.5 in the air. A decrease in such activities will positively impact the air concentration of PM2.5. As already stated above, an increase of the urban green areas can also positively impact PM2.5 concentration in the air through the air filtration service provided by these ecosystems.

BALIN TO COMPLETE/REVIEW?
<!--# Describe the main natural and anthropogenic factors that affecst the metric -->


## 4. Reference condition and levels

### 4.1 Reference condition
Ideally, the reference level should be 0.

BALIN TO COMPLETE/REVIEW?

<!--# Define the reference condition (or refer to where it is defined). Note the destinction between reference condition and reference levels 10.3897/oneeco.5.e58216  -->

### 4.2 Reference levels
This section is not revelvant as the indicator has not been normalised using a reference value.
<!--# 

If relevant (i.e. if you have normalised a variable), describe the reference levels used to normalise the variable. 

Use the terminology where X~0~ referes to the referece level (the variable value) denoting the worst possible condition; X~100~denotes the optimum or best possible condition; and X~*n*~, where in is between 0 and 100, denotes any other anchoring points linking the variable scale to the indicator scale (e.g. the threshold value between good and bad condition X~60^). 

Why was the current option chosen and how were the reference levels quantified? If the reference values are calculated as part of the analyses further down, please repeat the main information here.

 -->


#### 4.2.1 Spatial resolution and validity
This section is not revelvant as the indicator has not been normalised using a reference value.
<!--# 

Describe the spatial resolution of the reference levels. E.g. is it defined as a fixed value for all areas, or does it vary. Also, at what spatial scale are the reference levels valid? For example, if the reference levels have a regional resolution (varies between regions), it might mean that it is only valid and correct to use for normalising local variable values that are first aggregated to regional scale. However, sometimes the reference levels are insensitive to this and can be used to scale variables at the local (e.g. plot) scale. 

 -->

## 5. Uncertainties
There are two categories of uncertainties that can be considered with the development of this indicator and its subsequent use (@uncertainty):

- <u>Model uncertainty</u>: the data used to compile the air quality indicator all present a degree of uncertainty including spatial and temporal accuracies, the modelling approaches done to obtain the spatial layers especially the Grunnkart and the PM2.5 concentration maps. The maps for PM2.5 concentration have been modelled but the uncertainties pertaining to the results have not be assessed and clearly quantified. 

- <u>Decision uncertainty</u>: the indicators presented in this document have been compiled in accordance with different interpretations of the urban areas defined by Eurostat for the EU Regulation 2024/3024 (@eu-2024-3024). There are uncertainties due to the interpretations of the indicator and the methodological choices that resulted to calculate them. For example,  URAQ_000 relies on the assumption that urban areas in Norway equals the total extent of Local Administrative Units for which the variable DEGURBA equals 1. Inversely, URAQ_004 assumes that the total urban areas at national level should be represneted by the total area of the "Settelements and other artificial areas" ecosystem class from the EU Ecosystem Typology. All these interpretations and choices results in variability in the results of the different indicators. Finally, one have to consider the interpretation and applications of the results given in this document by the users. The translation of these indicators into decision-making will inherently present some uncertainties as it relies on the users' own experience, expertise and goals, which will influence the understanding of the indicators.
<!--# Describe the main uncertainties or sources of error in the indicator or the underlying data. -->

## 6. References
European Commission (2025). Ecosystem Condition Accounts - Guidance Note 6^{th} Draft. https://circabc.europa.eu/ui/group/922b4700-1c83-4099-b550-763badab3ec0/library/5074c555-99ea-4931-ace8-9351fa174f8b

European Council and Parliament (2024). Regulation (EU) 2024/3024 of the European Parliament and of the Council of 27 November 2024 amending Regulation (EU) No 691/2011 as regards introducing new environmental economic account modules. https://eur-lex.europa.eu/eli/reg/2024/3024/oj/eng

United Nations, (2024). System of Environmental Economic Accounting - Ecosystem Accounting.

Walther Franziska, Barton David N., Schwaab Jonas, Kato-Huerta Jarumi, Immerzeel Bart, Adamescu Mihai, Andersen Erling, Arámbula Coyote Martha Verónica, Arany Ildikó, Balzan Mario, Bruggeman Adriana, Carvalho-Santos Claudia, Cazacu Constantin, Geneletti Davide, Giuca Relu, Inácio Miguel, Lagabrielle Erwann, Lange Sabine, Clec’h Solen Le, Vanessa Lim Zhi Yi, Mörtberg Ulla, Nedkov Stoyan, Portela Ana Paula, Porucznik Anna, Racoviceanu Tudor, Rendón Paula, Ribeiro Daniela, Seguin Joana, Hribar Mateja Šmid, Stoycheva Vanya, Vejre Henrik, Zoumides Christos, Grêt-Regamey Adrienne, (2025). Uncertainties in ecosystem services assessments and their implications for decision support – A semi-systematic literature review. Ecosystem Services 73, 101714. https://doi.org/10.1016/j.ecoser.2025.101714

Wenting Wu and Yixin Zhang, (2018). Effects of particulate matter (PM2.5) and associated acidity on ecosystem functioning: response of leaf litter breakdown, Environmental Science and Pollution Research 25, 30720–30727. https://doi.org/10.1007/s11356-018-2922-1.

<!--# You can add references manually or use a citation manager and add intext citations as with crossreferencing and hyperlinks. See https://quarto.org/docs/authoring/footnotes-and-citations.html -->

## 7. Datasets
All the datasets used to compile the different versions of the URGR indicators have been thoroughly describe din the previous sections, links to them are also provided for more information.
<!--# Describe the unique datasets seperately under seperate headers (Dataset A, Dataset B, etc.-->

## 8. Spatial units
We have two spatial units in which the air quality indicator has been compiled: national and municipal. In terms of the SEEA-EA, our Ecosystem Accounting Area is the country of Norway (although Svalbård is not included). The Ecosystem Type of interest in the urban ecosystems. Finally, the minimum spatial units at which the results are broken down are the municipalities.
<!--# 

Describe the spatial units that you rely on in your analyses. Highlight the spatial units (the resolution) that the indicator values should be interpretted at. Potential spatial delineation data should eb introduced under 7.1. Datasets. We recomend using the SEEA EA terminology opf Basic Spatial Units (BSU), Ecosystem Asses (EA) and Ecosystem Accounting Area (EAA). 

-->

## 9. Analyses

### Paths to data sources
Before starting any of the analyses, we store the path in which the data will be found. If readers wish to download the data and run this code, they can just change the paths below to their local paths for the rest of the code to function.
```{r}
#| eval: false
#| code-summary: "Paths to the data"

# DEGURBA from Eurostat
path_degurba <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_DEGURBA_Eurostat/EU-27-LAU-2024-NUTS-2024.xlsx"

# LAUs shapefile from Eurostat
path_lau <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_Eurostat/LAU_RG_01M_2023_3035.shp"
path_lau_folder <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/LAU_Eurostat/"

# Municipalities from Kartverkert
path_kom <- "/data/R/GeoSpatialData/AdministrativeUnits/Norway_AdministrativeUnits/Original/Norway_Municipalities/Administrative enheter kommuner FGDB-format/Basisdata_0000_Norge_25833_Kommuner_FGDB/Basisdata_0000_Norge_25833_Kommuner_FGDB.gdb"

# Municipalities number 2023 and 2024
path_kom_nb <- "/data/P-Prosjekter2/412413_2023_no_egd/git_data/Adminstrative_boundaries_NO/NO_Fylke/kommune_fylke_region_NO_2024.xlsx"

# Grunnkart
path_grunnkart <- "/data/R/GeoSpatialData/LandUse/Norway_Arealregnskap/Original/GrunnkartArealregnskap FGDB-format/"

# Path to write results
res_path <- "/data/P-Prosjekter2/412413_2023_no_egd/Results/URAQ/"

```

### Define urban areas
In all the versions of the URAQ indicators defined in this document, the urban area is either defined as (i) the total area of Local Administrative Units (LAUs); (ii) the total area of EU Typology class "Settlements and Other Artificial Areas" (SOAA) within the LAUs; or (iii) the total area of SOAA in Norway. We need to create the relevant datasets for the compilation of areas (i) and (ii). Area (iii) is the total of all the areas (ii).

#### Local Administrative Units (LAUs)
The Local Administrative Units in Norway are the municipalities. A shapefile with the administrative boundaries of the municipalities is available from Eurostat. As we are not interested in the marine ecosystems, we chose to use Eurotat boundaries instead of those available nationally from Kartverkert as the boundaries excluded the sea. Unfortunately, Eurostat shapefile is from 2023, before the modification of municipalities that happened in 2024, we thus have to manipulate the shapefile from Eurostat to update it in for the municipalities Haram and Ålesund.
```{r}
#| eval: false
#| code-summary: "Update Eurotate LAUs to 2024"

# Read shapefile and select Norway
lau_no <- st_read(path_lau) %>%
           filter(CNTR_CODE == "NO")

# Read the shapefile from Kartverkert
kom_2024 <- st_read(path_kom, layer = "kommune")

# Select Haram and Ålesund municipalities
har_al_lau <- lau_no %>% 
                filter(LAU_ID == 1507)

har_al_kom <- kom_2024 %>%
                filter(kommunenummer == 1508 | kommunenummer == 1580) %>%
                st_transform(., st_crs(har_al_lau))

# Intersection between Eurostat LAU shapefile and Kartverkert 
# municipality shapefile for Haram and Ålesund municipalities 
kom_nb <- read_excel(path_kom_nb) %>%
            as.data.frame()
kom_nb$kommune_nr_2023[which(kom_nb$kommune_nr_2023 == "301")] <- "0301"

haram_2024 <- st_intersection(har_al_lau, har_al_kom[2,]) %>%
                select(c(colnames(lau_no), kommunenavn)) %>%
                select(!c(LAU_NAME)) %>%
                rename(LAU_NAME = kommunenavn) %>%
                left_join(., kom_nb, by = join_by("LAU_ID" == "kommune_nr_2023")) %>%
                select(LAU_NAME, fylke_nr, kommune_nr_2024, region_name, geometry)
haram_2024$kommune_nr_2024 <- 1580

alesund_2024 <- st_intersection(har_al_lau, har_al_kom[1,]) %>%
                select(colnames(lau_no)) %>%
                left_join(., kom_nb, by = join_by("LAU_ID" == "kommune_nr_2023")) %>%
                select(LAU_NAME, fylke_nr, kommune_nr_2024, region_name, geometry)

# Final LAUs shapefile
lau_no_2024 <- lau_no %>%
                filter(!LAU_ID == 1507) %>%
                left_join(., kom_nb, by = join_by("LAU_ID" == "kommune_nr_2023")) %>%
                select(LAU_NAME, fylke_nr, kommune_nr_2024, region_name, geometry) %>%
                rbind(., haram_2024, alesund_2024) %>%
                st_as_sf()
                
                
```

To compile the different versions of the URAQ indicators, we need to append to this shapefile the variable `DEGURBA`, which represent the degree of urbanisation of the municipality. This variable is produced at European level by Eurostat and is freely available. In the code below we join the `DEGURBA` variable to the municipality shapefile. We finish by exporting the shapefile for further analyses with duckdb in the next section.
```{r}
#| eval: false
#| code-summary: "Add the DEGURBA variable to the LAU dataset"

# Read excel file with Degurba variable and select Norway
degurba_lau_no <- read_excel(path_degurba, sheet = "NO")

degurba_lau_no$`LAU CODE` <- as.numeric(degurba_lau_no$`LAU CODE`)
degurba_lau_no$`LAU CODE`[which(degurba_lau_no$`LAU CODE` == 0301)] <- 301

# Join lau_no_2024 with DEGURBA
lau_dgurb <- inner_join(lau_no_2024,
                        degurba_lau_no,
                        by = join_by("kommune_nr_2024" == "LAU CODE")) %>%
              select(LAU_NAME, DEGURBA, fylke_nr, kommune_nr_2024, region_name, geometry) %>%
              st_as_sf()

# Export the LAUs updated shapefiles for 2024
# this is necessary for working with duckdb in the next section
st_write(lau_dgurb, paste0(path_lau_folder, "LAU_EUROSTAT_2024.shp"), append = FALSE)

# Clean the R environment
rm(list = setdiff(ls(), 
                  c("path_degurba",
                    "path_kom",
                    "path_kom_nb",
                    "path_lau",
                    "path_lau_folder",
                    "path_grunnkart",
                    "res_path",
                    "lau_dgurb")))

```


#### Settlements and Other Artificial Areas (SOAA) within LAUs
Defining SOAA within LAUs requires the LAUs and the extent of the SOAA ecosystem type. LAUs have been created at the step before. SOAA can be retrieved from the Grunnkart produced by NIBIO. To identify these areas, we need to run a spatial intersections between the LAUs and the SOAA class from the Grunnkart. Such intersections are however time consuming so we will do it with the `duckdb` package which allows to decrease significantly the time of computation. Note that sadly, the geometry of the Grunnkart tile of Fylke 34 had to be cleaned outside of `duckdb` and using `sf` as some topology exceptions could not be corrected.
```{r}
#| eval: false
#| code-summary: "Settlements per LAUs"
# Code by Jennifer Hansen & Sylvie Clappe

## Path to data
# Grunnkart
gdb_files <- list.files(path_grunnkart, pattern = "_gdb\\.gdb$", 
                        full.names = TRUE)

# LAUs 2024
path_lau_2024 <- paste0(path_lau_folder, "LAU_EUROSTAT_2024.shp")

## Clean Grunnkart tile 34
# Clean
grunnkart_34 <- st_read(gdb_files[8], query = "SELECT * FROM arealregnskap WHERE okosystemtype_1 = 'Settlements and other artificial areas'") %>%
                  st_transform(., crs = "EPSG:3035") %>%
                  st_buffer(., 0)

# Check
which(st_is_valid(grunnkart_34) == FALSE) %>% length()


## Database setup
conn <- dbConnect(duckdb())
ddbs_install(conn)
ddbs_load(conn)


## Limit the number of threads (cores) duckdb uses
dbExecute(conn, "PRAGMA threads = 30")


## Register grunnkart_34 in the duckdb database
ddbs_write_vector(conn, grunnkart_34, "grunnkart_valid_34")



# Check that the table was registered
ddbs_list_tables(conn)


## Write SQL queries to re-project the grunnkart and make its geometry valid
query_valid <-glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  ST_Transform(ST_MakeValid(geo), 'EPSG:25832', 'EPSG:3035', true) AS geom
  FROM grunnkart
  WHERE okosystemtype_1 = 'Settlements and other artificial areas'
")

query_valid_18_55 <- glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  ST_Transform(ST_MakeValid(geo), 'EPSG:25833', 'EPSG:3035', true) AS geom
  FROM grunnkart
  WHERE okosystemtype_1 = 'Settlements and other artificial areas'
")

query_valid_34 <- glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  geo AS geom
  FROM grunnkart_valid_34
  WHERE okosystemtype_1 = 'Settlements and other artificial areas'
")

query_valid_56 <- glue("
CREATE TABLE grunnkart_valid AS
SELECT
  okosystemtype_1,
  ST_Transform(ST_MakeValid(geo), 'EPSG: 25835', 'EPSG:3035', true) AS geom
  FROM grunnkart
  WHERE okosystemtype_1 = 'Settlements and other artificial areas'
")

query_intersect <- glue("
CREATE TABLE grunnkart_intersection AS
SELECT g.*, l.*
FROM grunnkart_valid g
JOIN lau_fylke l
ON ST_Intersects(g.geom, l.geom)")

query_drop <- glue("
ALTER TABLE grunnkart_intersection
DROP COLUMN geom_1")


## Intersection

# Create function to do the spatial intersection
# includes registration of grunnkart and its cleaning
do_intersection <- function(db_connexion, fylke, path_list, fylke_index_path_list, bd_path){
  
  if(fylke %in% c(3, 11, 15, 40, 42, 46, 31, 33, 32, 39, 50)){
    
    # Register Grunnkart for the specific fylke
    idx <- which(fylke_index_path_list == fylke)
    ar_path <- normalizePath(path_list[idx])
    ar_layer <- "arealregnskap"
    dbExecute(db_connexion, glue("
  CREATE VIEW grunnkart AS 
  SELECT *,
  FROM ST_Read('{ar_path}', layer='{ar_layer}')"))
    
    # Register LAU for specific Fylke
    lau_path <- bd_path
    dbExecute(db_connexion, glue("
  CREATE VIEW lau_fylke AS 
  SELECT *,
  FROM ST_Read('{bd_path}')"))
    
    # Spatial intersect to join the variables of both datasets before intersection
    dbExecute(db_connexion, query_valid)
    dbExecute(db_connexion, query_intersect)
    dbExecute(db_connexion, query_drop)
    
    # Perform spatial intersection
    soaa_lau <- ddbs_intersection(db_connexion, x = "grunnkart_intersection", y = "lau_fylke", crs = "EPSG:3035")
    
    # Drop the grunnkart register tables
    dbExecute(db_connexion, "DROP VIEW grunnkart")
    dbExecute(db_connexion, "DROP VIEW lau_fylke")
    dbExecute(db_connexion, "DROP TABLE grunnkart_valid")
    dbExecute(db_connexion, "DROP TABLE grunnkart_intersection")
    
    # Return the spatial intersection
    return(soaa_lau)
    
  } else if(fylke %in% c(18, 55)){
    
    # Register grunnkart for the specific fylke
    idx <- which(fylke_index_path_list == fylke)
    ar_path <- path_list[idx]
    ar_layer <- "arealregnskap"
    dbExecute(db_connexion, glue("
  CREATE VIEW grunnkart AS 
  SELECT *,
  FROM ST_Read('{ar_path}', layer='{ar_layer}')"))
    
    # Register LAU for specific Fylke
    lau_path <- bd_path
    dbExecute(db_connexion, glue("
  CREATE VIEW lau_fylke AS 
  SELECT *,
  FROM ST_Read('{bd_path}')"))
    
    # Spatial intersect to join the variables of both datasets before intersection
    dbExecute(db_connexion, query_valid_18_55)
    dbExecute(db_connexion, query_intersect)
    dbExecute(db_connexion, query_drop)
    
    # Perform spatial intersection
    soaa_lau <- ddbs_intersection(db_connexion, x = "grunnkart_intersection", y = "lau_fylke", crs = "EPSG:3035")
    
    # Drop the grunnkart register tables
    dbExecute(db_connexion, "DROP VIEW grunnkart")
    dbExecute(db_connexion, "DROP VIEW lau_fylke")
    dbExecute(db_connexion, "DROP TABLE grunnkart_valid")
    dbExecute(db_connexion, "DROP TABLE grunnkart_intersection")
    
    # Return the spatial intersection
    return(soaa_lau)
    
  } else if(fylke == 56){
    
    # Register Grunnkart for the specific fylke
    idx <- which(fylke_index_path_list == fylke)
    ar_path <- path_list[idx]
    ar_layer <- "arealregnskap"
    dbExecute(db_connexion, glue("
  CREATE VIEW grunnkart AS 
  SELECT *,
  FROM ST_Read('{ar_path}', layer='{ar_layer}')"))
    
    # Register LAU for specific Fylke
    lau_path <- bd_path
    dbExecute(db_connexion, glue("
  CREATE VIEW lau_fylke AS 
  SELECT *,
  FROM ST_Read('{bd_path}')"))
    
    # Spatial intersect to join the variables of both datasets before intersection
    dbExecute(db_connexion, query_valid_56)
    dbExecute(db_connexion, query_intersect)
    dbExecute(db_connexion, query_drop)
    
    # Perform spatial intersection
    soaa_lau <- ddbs_intersection(db_connexion, x = "grunnkart_intersection", y = "lau_fylke", crs = "EPSG:3035")
    
    # Drop the grunnkart register tables
    dbExecute(db_connexion, "DROP VIEW grunnkart")
    dbExecute(db_connexion, "DROP VIEW lau_fylke")
    dbExecute(db_connexion, "DROP TABLE grunnkart_valid")
    dbExecute(db_connexion, "DROP TABLE grunnkart_intersection")
    
    return(soaa_lau)
    
  } else if(fylke == 34){
    
    # Register LAU for specific Fylke
    lau_path <- bd_path
    dbExecute(db_connexion, glue("
  CREATE VIEW lau_fylke AS 
  SELECT *,
  FROM ST_Read('{bd_path}')"))
    
    # Spatial intersect to join the variables of both datasets before intersection
    dbExecute(db_connexion, query_valid_34)
    dbExecute(db_connexion, query_intersect)
    dbExecute(db_connexion, query_drop)
    
    # Perform spatial intersection
    soaa_lau <- ddbs_intersection(db_connexion, x = "grunnkart_intersection", y = "lau_fylke", crs = "EPSG:3035")
    
    # Drop the grunnkart register tables
    dbExecute(db_connexion, "DROP VIEW lau_fylke")
    dbExecute(db_connexion, "DROP TABLE grunnkart_valid")
    dbExecute(db_connexion, "DROP TABLE grunnkart_intersection")
    
    return(soaa_lau)
    
  } else (retrun("an error has occured"))
  
}

# Create the input to the intersection function
numextract <- function(string){str_extract(string, "[-+]?[0-9]*\\.?[0-9]+")
}  
fylke_nb_gdb_vec <- map(seq_along(gdb_files), ~ numextract(gdb_files[.x])) %>%
                      unlist() %>%
                      as.numeric()

# Perform the intersection
soaa_lau_inter <- map(seq_along(fylke_nb_gdb_vec), 
                      ~ do_intersection(conn, fylke_nb_gdb_vec[.x], gdb_files, fylke_nb_gdb_vec, path_lau_2024))


# Close the connection to duckdb database (remove in-memory dB)
dbDisconnect(conn)

# Clean the R environment
rm(list = setdiff(ls(), 
                  c("path_degurba",
                    "path_kom",
                    "path_kom_nb",
                    "path_lau",
                    "path_lau_folder",
                    "path_grunnkart",
                    "res_path",
                    "soaa_lau_inter",
                    "lau_dgurb")))
```


### PM2.5 concentration
#### Load the data
We can now read in the PM2.5 concentration maps for each of the municipalities. As the PM2.5 maps are available from Miljødirektoratet website using an API, we first create a list of the maps that should be accessed before retrieving the data through the API. The PM2.5 maps are retrieved in .tif format. Note that the data have to be called through the API and written on the disk. Due to their format, they couldn't be loaded in the R environment. The code below shows how to retrieve the data and write them on a chosen folder in your computer. If you do not nee dto run this code, go to the next step.
```{r}
#| eval: false
#| code-summary: "Load PM2.5 concentration maps and store them on disk"

## Create list of urls

# Base url
begin_url <- "https://airquality-expert.met.no/airqualityexpert/0.2/map/"
end_url <- "/pm25_concentration_annualmean.tif"

# List of municipalities numbers
path_lau_2024 <- paste0(path_lau_folder, "LAU_EUROSTAT_2024.shp")
lau_2024 <- st_read(path_lau_2024)

lau_nb <- unique(lau_2024$k__2024) %>%
            as.character()
lau_nb[35] <- "0301"

# List the years of interest
yrs <- seq(2016, 2023, 1)

# Create the urls
url_list <- map(seq_along(yrs), 
                ~ map_chr(seq_along(lau_nb), 
                          function(y) {paste0(begin_url,
                                       lau_nb[y],
                                       "/",
                                       yrs[.x],
                                       end_url)}
                          )
                )


## Write API query function: retrieve the data and write them on the disk
api_fetch_data <- function(year_vec, municipality_vec, year, municipality, res_path, url_list){

idx_year <- which(year_vec == year)
idx_municip <- which(municipality_vec == municipality)

# Create a request
req <- request(url_list[[idx_year]][idx_municip])

# Perform the request
fetch_data <- req %>% 
               req_perform()

# Write data in GIS folder
resp_body_raw(fetch_data) %>% 
  writeBin(., paste0(res_path, year, "/PM25_", year, "_", municipality, ".tif"))
}


## Retrive and write the PM2.5 data on the disk
map(seq_along(yrs), 
    ~ map(seq_along(lau_nb), function(y) {
      api_fetch_data(yrs, 
                     lau_nb, 
                     yrs[.x], 
                     lau_nb[y], 
                     res_path = "/data/P-Prosjekter2/412413_2023_no_egd/git_data/PM2.5/",
                     url_list = url_list)}
      
      )
          )

## Clean the R environment
rm(list = setdiff(ls(), 
                  c("path_degurba",
                    "path_kom",
                    "path_kom_nb",
                    "path_lau",
                    "path_lau_folder",
                    "path_grunnkart",
                    "res_path",
                    "soaa_lau_inter",
                    "lau_dgurb",
                    "yrs",
                    "lau_nb")))
```

#### Extract PM2.5 concentration in urban areas
Urban areas are define din two ways in this project: (1) the total area of the LAU; or (2) the total area of the class "Settlements and other artificial areas" (SOAA), from the EU Ecosystem Typology, within the LAUs. The mean concentration of PM2.5for case (1) is easy to get as it can be calculated based on the entire PM2.5 concentration maps that we downloaded above. For case (2) however, further manipulations are needed as we need to only extract the raster cells of the PM2.5 concentration maps that overlap with the SOAA polygons. This is what we do in the code below. Note that the function used for this (`exact_extract()`) only works if the geometry type is polygon or multipolygon. Hence, we first need to clean the SOAA maps that we created before to only extract the polygons. 

During the extraction of the raster cell values, there will be the creation of "NA" values. This means that some polygon will have a PM2.5 concentration of "NA". This is an artifact due to the raster format of the PM2.5 concentration maps. While comparing them with the polygon of the municipalities, we noticed that some municipal raster maps were smaller than their associated municipal polygon.Hence, some polygons of settlements sadly fall outside of the PM2.5 concentration map while being in the municipal polygon. This leads to the creation of "NA" values. We added a step of cleaning in the code below to remove these "NA" values.

One last note on the code below: to speed up the computation time, parallel computing has been used through the new `in_parallel()` function from the `purrr` package. This requires to make some adjustments in the code to make sure that the `workers`, or jobs running in parallel, have the objects present in  the R environment and the packages. Indeed, when using `in_parallel()`, all packages and R objects of the environment are invisible to the `workers` if not explicitly stated in the `in_parallel()` function.

```{r}
#| eval: false
#| code-summary: "Compile PM2.5 concentration in urban areas"

## Iteration variables (if the code above hasn't been run)
# List of municipalities numbers 
path_lau_2024 <- paste0(path_lau_folder, "LAU_EUROSTAT_2024.shp")
lau_2024 <- st_read(path_lau_2024)

lau_nb <- unique(lau_2024$k__2024) %>%
            as.character()
lau_nb[35] <- "0301"

# List the years of interest
yrs <- seq(2016, 2023, 1)

## Clean SOAA: keep only polygons
daemons(15)
soaa_lau <-  soaa_lau_inter %>%
              map(., in_parallel(~ sf:::st_collection_extract(.x,
                    type = "POLYGON", 
                    warn = FALSE))) %>%
              compact() %>%  
              bind_rows()

daemons(0)
  

## Create function to read the raster and extract the raster cells corresponding to SOOA
# extract_rast <- function(path_rast_folder, soaa_shp, municipality, year){
# 
#   # Load packages so they are available in environement fo the worker for parallel computing
#   library(dplyr)
#   library(sf)
#   library(terra)
#   library(exactextractr)
# 
#   # Read in data
#   municip_rast <- rast(paste0(path_rast_folder, year, "/PM25_", year, "_", municipality, ".tif"))
#   soaa_bd <- soaa_shp %>%
#               filter(k__2024 == as.numeric(municipality)) %>%
#               st_transform(., crs(municip_rast)) %>%
#               mutate(soaa_area_m2 = unclass(st_area(.)))
# 
#   # Extract raster cells
#   soaa_lau_pm25 <- soaa_bd %>%
#                     exact_extract(municip_rast,
#                                   .,
#                                   fun = c("mean"),
#                                   append_cols = TRUE) %>%
#                     filter(!is.na(mean) == TRUE) %>%  # Cleaning step
#                     mutate(., year = year)
#   return(soaa_lau_pm25)
# }

extract_rast <- function(path_rast_folder, soaa_shp, municipality, year){

  # Load packages so they are available in environment fo the worker for parallel computing
  library(dplyr)
  library(sf)
  library(terra)
  library(exactextractr)

  # Read in data
  municip_rast <- rast(paste0(path_rast_folder, year, "/PM25_", year, "_", municipality, ".tif"))
  soaa_bd <- soaa_shp %>%
              st_transform(., crs(municip_rast)) %>%
              mutate(soaa_area_m2 = unclass(st_area(.)))

  # Extract raster cells
  soaa_lau_pm25 <- soaa_bd %>%
                    exact_extract(municip_rast,
                                  .,
                                  fun = c("mean"),
                                  append_cols = TRUE) %>%
                    filter(!is.na(mean) == TRUE) %>%  # Cleaning step
                    mutate(., year = year)
  return(soaa_lau_pm25)
}

## Extract PM2.5 mean concentration per SOAA polygon
daemons(4)
sooa_pm25 <- map(seq_along(lau_nb[1]), function(municipality_idx){
  
  # Filter municipality
  municipality_code <- lau_nb[municipality_idx]
  soaa_filtered <- soaa_lau %>%
                    filter(k__2024 == as.numeric(municipality_code))
  
  # Parallelise the extraction of PM2.5 cells for each year
  
  pm25_cells <- map(seq_along(yrs), in_parallel(function(j){
      extract_rast(
      path_rast_folder = "/data/P-Prosjekter2/412413_2023_no_egd/git_data/PM2.5/",
      soaa_shp = soaa_filtered,
      municipality = municipality_code,
      year = yrs[j]
    )
    }, extract_rast = extract_rast,
    soaa_filtered = soaa_filtered,
    municipality_code = municipality_code,
    yrs = yrs))
  
  return(pm25_cells)
  
  })
daemons(0)

# Using future_map() from furrr
# plan(multisession, workers = 4)
# sooa_pm25 <- map(seq_along(lau_nb[1]), function(municipality_idx){
#   
#   # Filter municipality
#   municipality_code <- lau_nb[municipality_idx]
#   soaa_filtered <- soaa_lau %>%
#                     filter(k__2024 == as.numeric(municipality_code))
#   
#   # Parallelise the extraction of PM2.5 cells for each year
#   
#   pm25_cells <- future_map(seq_along(yrs), function(j){
#       extract_rast(
#       path_rast_folder = "/data/P-Prosjekter2/412413_2023_no_egd/git_data/PM2.5/",
#       soaa_shp = soaa_filtered,
#       municipality = municipality_code,
#       year = yrs[j]
#     )}, .options = furrr_options(seed = TRUE))
#   
#   return(pm25_cells)
#   
#   })


## Clean the R environment
rm(list = setdiff(ls(), 
                  c("path_degurba",
                    "path_kom",
                    "path_kom_nb",
                    "path_lau",
                    "path_lau_folder",
                    "path_grunnkart",
                    "res_path",
                    "soaa_lau_inter",
                    "lau_dgurb",
                    "yrs",
                    "lau_nb",
                    "soaa_pm25")))
```

#### Compile mean PM2.5 concentration in urban areas
Now that we have the PM2.5 concentration for the whole municipalities (PM2.5 raster maps), and within the SOAA of municipalities (see section above), we can calculate the mean concentration over both these areas.
```{r}
#| eval: false
#| code-summary: "Mean PM2.5 concentration in urban areas"

## Average PM2.5 in the municipality
# Create an averaging function
read_and_compile_pm25 <- function(path_rast_folder, year, municipality){
  
  # Load libraries for workers
  library(terra)
  library(dplyr)
  
  # Read in data
  municip_rast <- rast(paste0(path_rast_folder, year, "/PM25_", year, "_", municipality, ".tif"))
  
  # Average
  av_pm25_municip <- values(municip_rast) %>% 
                      .[!is.na(.)] %>%
                      mean()
  
  # Return a vector of results
  res <- data.frame(mean_pm25_municip = av_pm25_municip, 
                    year = year, 
                    kommune_nummer = as.numeric(municipality))
  
  return(res)
                      
}

# Run the averaging function
daemons(10)

all_combinations <- expand.grid(seq_yrs = seq_along(yrs), seq_lau_nb = seq_along(lau_nb))

municip_pm25_av <- map2(all_combinations$seq_yrs, all_combinations$seq_lau_nb,
                   in_parallel(function(x, y){
                     read_and_compile_pm25(path_rast_folder = "/data/P-Prosjekter2/412413_2023_no_egd/git_data/PM2.5/",
                                           year = yrs[x], 
                                           municipality = lau_nb[y]
                                           )
                                        }
                              ),
                     read_and_compile_pm25 = read_and_compile_pm25,
                     lau_nb = lau_nb, 
                     yrs = yrs
                     )
daemons(0)

# municip_pm25_av <- map(seq_along(yrs), 
#                     ~ map(seq_along(lau_nb), function(y) {read_and_compile_pm25(path_rast_folder = "/data/P-Prosjekter2/412413_2023_no_egd/git_data/PM2.5/",
#                                                                                 year = yrs[.x], municipality = lau_nb[y])}
#                        )
#                  ) %>%
#                     compact() %>%
#                     bind_rows()



## Average PM2.5 in the SOAA of the municipality
soaa_pm25_av <- soaa_pm25 %>%
                  compact() %>%
                  bind_rows() %>%
                  rename(kommune_nummer = k__2024) %>%
                  group_by(year, fylk_nr, kommune_nummer) %>%
                  summarise(mean_soaa_pm25_ug_m3 = mean(mean),
                            total_soaa_area_m2 = sum(soaa_area_m2))
```

### Summary table to derive URAQ
Now we can build an overall table that we will be able to use to calculate all the versions of the URAQ indicator in the Results section below.

```{r}
#| eval: false
#| code-summary: "Summary table"
## Create tables of results
res_table_pm25 <- inner_join(soaa_pm25_av, municip_pm25_av, by = c("year", "kommune_nummer")) %>%
                    select(year, fylk_nr, kommune_nummer, mean_pm25_municip, mean_soaa_pm25_ug_m3, total_soaa_area_m2)
                    

## Export tables of results
write.table(res_table_pm25, paste0(res_path, "URAQ_summary_table.csv"), sep = ";")
```

<!--# 

Use this header for documenting the analyses. Put code in seperate code chunks, and annotate the code in between using normal text (i.e. between the chunks, and try to avoid too many hashed out comments inside the code chunks). Add subheaders as needed. 

Code folding is activated, meaning the code will be hidden by default in the html (one can click to expand it).

Caching is also activated (from the top YAML), meaning that rendering to html will be quicker the second time you do it. This will create a folder inside you project folder (called INDICATORID_cache). Sometimes caching created problems because some operations are not rerun when they should be rerun. Try deleting the cash folder and try again.

-->

## 10. Results

<!--# 

Repeat the final results here. Typically this is a map or table of indicator values.

This is typically where people will harvest data from, so make sure to include all relevant output here, but don't clutter this section with too much output either.

-->

## 11. Export file

<!--# 

Optional: Display the code (don't execute it) or the workflow for exporting the indicator values to file. Ideally the indicator values are exported as a georeferenced shape or raster file with indicators values, reference values and errors. You can also chose to export the raw (un-normalised or unscaled variable) as a seperate product. You should not save large sptaial output data on GitHub. You can use eval=FALSE to avoid code from being executed (example below - delete if not relevant) 

-->

```{r export}
#| eval: false
```
